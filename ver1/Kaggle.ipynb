{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9610f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/Users/poraya/AI-project/train.csv'):\n",
    "     for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36481a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries, classes, and functions \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler, StandardScaler, RobustScaler \n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import mutual_info_regression \n",
    "from sklearn.decomposition import PCA, TruncatedSVD  \n",
    "from sklearn.compose import make_column_transformer \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, KFold, StratifiedKFold, StratifiedShuffleSplit  \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier  \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score \n",
    "\n",
    "\n",
    "# Set random seed \n",
    "SEED = np.random.default_rng().integers(99999)\n",
    "# SEED = 999999 \n",
    "from tensorflow.keras.utils import set_random_seed \n",
    "set_random_seed = SEED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3840816",
   "metadata": {},
   "source": [
    "Step1.1 Import train.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa196443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n",
      "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
      "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
      "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
      "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
      "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
      "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
      "\n",
      "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
      "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
      "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
      "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
      "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
      "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
      "\n",
      "   Transported  \n",
      "0        False  \n",
      "1         True  \n",
      "2        False  \n",
      "3        False  \n",
      "4         True   \n",
      " None \n",
      "                count unique             top  freq        mean          std  \\\n",
      "PassengerId     8693   8693         0001_01     1         NaN          NaN   \n",
      "HomePlanet      8492      3           Earth  4602         NaN          NaN   \n",
      "CryoSleep       8476      2           False  5439         NaN          NaN   \n",
      "Cabin           8494   6560         G/734/S     8         NaN          NaN   \n",
      "Destination     8511      3     TRAPPIST-1e  5915         NaN          NaN   \n",
      "Age           8514.0    NaN             NaN   NaN    28.82793    14.489021   \n",
      "VIP             8490      2           False  8291         NaN          NaN   \n",
      "RoomService   8512.0    NaN             NaN   NaN  224.687617   666.717663   \n",
      "FoodCourt     8510.0    NaN             NaN   NaN  458.077203   1611.48924   \n",
      "ShoppingMall  8485.0    NaN             NaN   NaN  173.729169   604.696458   \n",
      "Spa           8510.0    NaN             NaN   NaN  311.138778  1136.705535   \n",
      "VRDeck        8505.0    NaN             NaN   NaN  304.854791  1145.717189   \n",
      "Name            8493   8473  Gollux Reedall     2         NaN          NaN   \n",
      "Transported     8693      2            True  4378         NaN          NaN   \n",
      "\n",
      "              min   25%   50%   75%      max  \n",
      "PassengerId   NaN   NaN   NaN   NaN      NaN  \n",
      "HomePlanet    NaN   NaN   NaN   NaN      NaN  \n",
      "CryoSleep     NaN   NaN   NaN   NaN      NaN  \n",
      "Cabin         NaN   NaN   NaN   NaN      NaN  \n",
      "Destination   NaN   NaN   NaN   NaN      NaN  \n",
      "Age           0.0  19.0  27.0  38.0     79.0  \n",
      "VIP           NaN   NaN   NaN   NaN      NaN  \n",
      "RoomService   0.0   0.0   0.0  47.0  14327.0  \n",
      "FoodCourt     0.0   0.0   0.0  76.0  29813.0  \n",
      "ShoppingMall  0.0   0.0   0.0  27.0  23492.0  \n",
      "Spa           0.0   0.0   0.0  59.0  22408.0  \n",
      "VRDeck        0.0   0.0   0.0  46.0  24133.0  \n",
      "Name          NaN   NaN   NaN   NaN      NaN  \n",
      "Transported   NaN   NaN   NaN   NaN      NaN   \n",
      " PassengerId     8693\n",
      "HomePlanet         3\n",
      "CryoSleep          2\n",
      "Cabin           6560\n",
      "Destination        3\n",
      "Age               80\n",
      "VIP                2\n",
      "RoomService     1273\n",
      "FoodCourt       1507\n",
      "ShoppingMall    1115\n",
      "Spa             1327\n",
      "VRDeck          1306\n",
      "Name            8473\n",
      "Transported        2\n",
      "dtype: int64 \n",
      " PassengerId       0\n",
      "HomePlanet      201\n",
      "CryoSleep       217\n",
      "Cabin           199\n",
      "Destination     182\n",
      "Age             179\n",
      "VIP             203\n",
      "RoomService     181\n",
      "FoodCourt       183\n",
      "ShoppingMall    208\n",
      "Spa             183\n",
      "VRDeck          188\n",
      "Name            200\n",
      "Transported       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import training dataset into padas DataFrame & explore \n",
    "train = pd.read_csv('/Users/poraya/Documents/AI-project/train.csv') \n",
    "\n",
    "print(train.head(), '\\n', \n",
    "train.info(), '\\n', \n",
    "train.describe(include='all').T, '\\n', \n",
    "train.nunique() , '\\n', \n",
    "train.isna().sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75f666",
   "metadata": {},
   "source": [
    "Step1.2 Import test.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7db3bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4277 entries, 0 to 4276\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   4277 non-null   object \n",
      " 1   HomePlanet    4190 non-null   object \n",
      " 2   CryoSleep     4184 non-null   object \n",
      " 3   Cabin         4177 non-null   object \n",
      " 4   Destination   4185 non-null   object \n",
      " 5   Age           4186 non-null   float64\n",
      " 6   VIP           4184 non-null   object \n",
      " 7   RoomService   4195 non-null   float64\n",
      " 8   FoodCourt     4171 non-null   float64\n",
      " 9   ShoppingMall  4179 non-null   float64\n",
      " 10  Spa           4176 non-null   float64\n",
      " 11  VRDeck        4197 non-null   float64\n",
      " 12  Name          4183 non-null   object \n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 434.5+ KB\n",
      "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
      "0     0013_01      Earth      True  G/3/S  TRAPPIST-1e  27.0  False   \n",
      "1     0018_01      Earth     False  F/4/S  TRAPPIST-1e  19.0  False   \n",
      "2     0019_01     Europa      True  C/0/S  55 Cancri e  31.0  False   \n",
      "3     0021_01     Europa     False  C/1/S  TRAPPIST-1e  38.0  False   \n",
      "4     0023_01      Earth     False  F/5/S  TRAPPIST-1e  20.0  False   \n",
      "\n",
      "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck              Name  \n",
      "0          0.0        0.0           0.0     0.0     0.0   Nelly Carsoning  \n",
      "1          0.0        9.0           0.0  2823.0     0.0    Lerome Peckers  \n",
      "2          0.0        0.0           0.0     0.0     0.0   Sabih Unhearfus  \n",
      "3          0.0     6652.0           0.0   181.0   585.0  Meratz Caltilter  \n",
      "4         10.0        0.0         635.0     0.0     0.0   Brence Harperez   \n",
      " None \n",
      "                count unique          top  freq        mean          std  min  \\\n",
      "PassengerId     4277   4277      0013_01     1         NaN          NaN  NaN   \n",
      "HomePlanet      4190      3        Earth  2263         NaN          NaN  NaN   \n",
      "CryoSleep       4184      2        False  2640         NaN          NaN  NaN   \n",
      "Cabin           4177   3265      G/160/P     8         NaN          NaN  NaN   \n",
      "Destination     4185      3  TRAPPIST-1e  2956         NaN          NaN  NaN   \n",
      "Age           4186.0    NaN          NaN   NaN   28.658146    14.179072  0.0   \n",
      "VIP             4184      2        False  4110         NaN          NaN  NaN   \n",
      "RoomService   4195.0    NaN          NaN   NaN  219.266269   607.011289  0.0   \n",
      "FoodCourt     4171.0    NaN          NaN   NaN  439.484296  1527.663045  0.0   \n",
      "ShoppingMall  4179.0    NaN          NaN   NaN  177.295525   560.821123  0.0   \n",
      "Spa           4176.0    NaN          NaN   NaN  303.052443  1117.186015  0.0   \n",
      "VRDeck        4197.0    NaN          NaN   NaN  310.710031  1246.994742  0.0   \n",
      "Name            4183   4176   Cints Erle     2         NaN          NaN  NaN   \n",
      "\n",
      "               25%   50%   75%      max  \n",
      "PassengerId    NaN   NaN   NaN      NaN  \n",
      "HomePlanet     NaN   NaN   NaN      NaN  \n",
      "CryoSleep      NaN   NaN   NaN      NaN  \n",
      "Cabin          NaN   NaN   NaN      NaN  \n",
      "Destination    NaN   NaN   NaN      NaN  \n",
      "Age           19.0  26.0  37.0     79.0  \n",
      "VIP            NaN   NaN   NaN      NaN  \n",
      "RoomService    0.0   0.0  53.0  11567.0  \n",
      "FoodCourt      0.0   0.0  78.0  25273.0  \n",
      "ShoppingMall   0.0   0.0  33.0   8292.0  \n",
      "Spa            0.0   0.0  50.0  19844.0  \n",
      "VRDeck         0.0   0.0  36.0  22272.0  \n",
      "Name           NaN   NaN   NaN      NaN   \n",
      " PassengerId     4277\n",
      "HomePlanet         3\n",
      "CryoSleep          2\n",
      "Cabin           3265\n",
      "Destination        3\n",
      "Age               79\n",
      "VIP                2\n",
      "RoomService      842\n",
      "FoodCourt        902\n",
      "ShoppingMall     715\n",
      "Spa              833\n",
      "VRDeck           796\n",
      "Name            4176\n",
      "dtype: int64 \n",
      " PassengerId       0\n",
      "HomePlanet       87\n",
      "CryoSleep        93\n",
      "Cabin           100\n",
      "Destination      92\n",
      "Age              91\n",
      "VIP              93\n",
      "RoomService      82\n",
      "FoodCourt       106\n",
      "ShoppingMall     98\n",
      "Spa             101\n",
      "VRDeck           80\n",
      "Name             94\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import test dataset into padas DataFrame & explore \n",
    "test = pd.read_csv('/Users/poraya/Documents/AI-project/test.csv') \n",
    "\n",
    "print(test.head(), '\\n', \n",
    "test.info(), '\\n', \n",
    "test.describe(include='all').T, '\\n', \n",
    "test.nunique() , '\\n', \n",
    "test.isna().sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60451a80",
   "metadata": {},
   "source": [
    "Step1.3 Merge train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74d2ff61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12970 entries, 0 to 4276\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   12970 non-null  object \n",
      " 1   HomePlanet    12682 non-null  object \n",
      " 2   CryoSleep     12660 non-null  object \n",
      " 3   Cabin         12671 non-null  object \n",
      " 4   Destination   12696 non-null  object \n",
      " 5   Age           12700 non-null  float64\n",
      " 6   VIP           12674 non-null  object \n",
      " 7   RoomService   12707 non-null  float64\n",
      " 8   FoodCourt     12681 non-null  float64\n",
      " 9   ShoppingMall  12664 non-null  float64\n",
      " 10  Spa           12686 non-null  float64\n",
      " 11  VRDeck        12702 non-null  float64\n",
      " 12  Name          12676 non-null  object \n",
      " 13  Transported   8693 non-null   object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 1.5+ MB\n",
      "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
      "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
      "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
      "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
      "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
      "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
      "\n",
      "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
      "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
      "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
      "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
      "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
      "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
      "\n",
      "  Transported  \n",
      "0       False  \n",
      "1        True  \n",
      "2       False  \n",
      "3       False  \n",
      "4        True   \n",
      " None \n",
      "                 count unique               top   freq        mean  \\\n",
      "PassengerId     12970  12970           0001_01      1         NaN   \n",
      "HomePlanet      12682      3             Earth   6865         NaN   \n",
      "CryoSleep       12660      2             False   8079         NaN   \n",
      "Cabin           12671   9825           G/734/S      8         NaN   \n",
      "Destination     12696      3       TRAPPIST-1e   8871         NaN   \n",
      "Age           12700.0    NaN               NaN    NaN   28.771969   \n",
      "VIP             12674      2             False  12401         NaN   \n",
      "RoomService   12707.0    NaN               NaN    NaN  222.897852   \n",
      "FoodCourt     12681.0    NaN               NaN    NaN  451.961675   \n",
      "ShoppingMall  12664.0    NaN               NaN    NaN  174.906033   \n",
      "Spa           12686.0    NaN               NaN    NaN  308.476904   \n",
      "VRDeck        12702.0    NaN               NaN    NaN  306.789482   \n",
      "Name            12676  12629  Carry Contrevins      2         NaN   \n",
      "Transported      8693      2              True   4378         NaN   \n",
      "\n",
      "                      std  min   25%   50%   75%      max  \n",
      "PassengerId           NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "HomePlanet            NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "CryoSleep             NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "Cabin                 NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "Destination           NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "Age             14.387261  0.0  19.0  27.0  38.0     79.0  \n",
      "VIP                   NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "RoomService    647.596664  0.0   0.0   0.0  49.0  14327.0  \n",
      "FoodCourt     1584.370747  0.0   0.0   0.0  77.0  29813.0  \n",
      "ShoppingMall    590.55869  0.0   0.0   0.0  29.0  23492.0  \n",
      "Spa           1130.279641  0.0   0.0   0.0  57.0  22408.0  \n",
      "VRDeck        1180.097223  0.0   0.0   0.0  42.0  24133.0  \n",
      "Name                  NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "Transported           NaN  NaN   NaN   NaN   NaN      NaN   \n",
      " PassengerId     12970\n",
      "HomePlanet          3\n",
      "CryoSleep           2\n",
      "Cabin            9825\n",
      "Destination         3\n",
      "Age                80\n",
      "VIP                 2\n",
      "RoomService      1578\n",
      "FoodCourt        1953\n",
      "ShoppingMall     1367\n",
      "Spa              1679\n",
      "VRDeck           1642\n",
      "Name            12629\n",
      "Transported         2\n",
      "dtype: int64 \n",
      " PassengerId        0\n",
      "HomePlanet       288\n",
      "CryoSleep        310\n",
      "Cabin            299\n",
      "Destination      274\n",
      "Age              270\n",
      "VIP              296\n",
      "RoomService      263\n",
      "FoodCourt        289\n",
      "ShoppingMall     306\n",
      "Spa              284\n",
      "VRDeck           268\n",
      "Name             294\n",
      "Transported     4277\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# merge test and train datasets into single dataframe for data cleaning and necessary pre-processing \n",
    "all = pd.concat([train, test], axis=0) \n",
    "\n",
    "print(all.head(), '\\n', \n",
    "all.info(), '\\n', \n",
    "all.describe(include='all').T, '\\n', \n",
    "all.nunique() , '\\n', \n",
    "all.isna().sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bfded5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      object\n",
      "HomePlanet       object\n",
      "CryoSleep        object\n",
      "Cabin            object\n",
      "Destination      object\n",
      "Age             float64\n",
      "VIP              object\n",
      "RoomService     float64\n",
      "FoodCourt       float64\n",
      "ShoppingMall    float64\n",
      "Spa             float64\n",
      "VRDeck          float64\n",
      "Name             object\n",
      "Transported      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# drop duplicate rows \n",
    "all.drop_duplicates(keep='first', inplace=True) \n",
    "print(all.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ed5d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age',\n",
      "       'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',\n",
      "       'Name', 'Transported', 'group', 'id', 'deck', 'cabin_no', 'side',\n",
      "       'FName', 'LName'],\n",
      "      dtype='object')\n",
      "                count unique               top   freq        mean  \\\n",
      "PassengerId     12970  12970           0001_01      1         NaN   \n",
      "HomePlanet      12682      3             Earth   6865         NaN   \n",
      "CryoSleep       12660      2             False   8079         NaN   \n",
      "Cabin           12671   9825           G/734/S      8         NaN   \n",
      "Destination     12696      3       TRAPPIST-1e   8871         NaN   \n",
      "Age           12700.0    NaN               NaN    NaN   28.771969   \n",
      "VIP             12674      2             False  12401         NaN   \n",
      "RoomService   12707.0    NaN               NaN    NaN  222.897852   \n",
      "FoodCourt     12681.0    NaN               NaN    NaN  451.961675   \n",
      "ShoppingMall  12664.0    NaN               NaN    NaN  174.906033   \n",
      "Spa           12686.0    NaN               NaN    NaN  308.476904   \n",
      "VRDeck        12702.0    NaN               NaN    NaN  306.789482   \n",
      "Name            12676  12629  Carry Contrevins      2         NaN   \n",
      "Transported    8693.0    NaN               NaN    NaN    0.503624   \n",
      "group           12970   9280              6499      8         NaN   \n",
      "id              12970      8                01   9280         NaN   \n",
      "deck            12671      8                 F   4239         NaN   \n",
      "cabin_no        12671   1894                82     34         NaN   \n",
      "side            12671      2                 S   6381         NaN   \n",
      "FName           12676   2883             Luise     16         NaN   \n",
      "LName           12676   2406         Buckentry     19         NaN   \n",
      "\n",
      "                      std  min   25%   50%   75%      max  \n",
      "PassengerId           NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "HomePlanet            NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "CryoSleep             NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "Cabin                 NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "Destination           NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "Age             14.387261  0.0  19.0  27.0  38.0     79.0  \n",
      "VIP                   NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "RoomService    647.596664  0.0   0.0   0.0  49.0  14327.0  \n",
      "FoodCourt     1584.370747  0.0   0.0   0.0  77.0  29813.0  \n",
      "ShoppingMall    590.55869  0.0   0.0   0.0  29.0  23492.0  \n",
      "Spa           1130.279641  0.0   0.0   0.0  57.0  22408.0  \n",
      "VRDeck        1180.097223  0.0   0.0   0.0  42.0  24133.0  \n",
      "Name                  NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "Transported      0.500016  0.0   0.0   1.0   1.0      1.0  \n",
      "group                 NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "id                    NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "deck                  NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "cabin_no              NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "side                  NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "FName                 NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "LName                 NaN  NaN   NaN   NaN   NaN      NaN  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12970 entries, 0 to 4276\n",
      "Data columns (total 21 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   12970 non-null  object \n",
      " 1   HomePlanet    12682 non-null  object \n",
      " 2   CryoSleep     12660 non-null  object \n",
      " 3   Cabin         12671 non-null  object \n",
      " 4   Destination   12696 non-null  object \n",
      " 5   Age           12700 non-null  float64\n",
      " 6   VIP           12674 non-null  object \n",
      " 7   RoomService   12707 non-null  float64\n",
      " 8   FoodCourt     12681 non-null  float64\n",
      " 9   ShoppingMall  12664 non-null  float64\n",
      " 10  Spa           12686 non-null  float64\n",
      " 11  VRDeck        12702 non-null  float64\n",
      " 12  Name          12676 non-null  object \n",
      " 13  Transported   8693 non-null   float64\n",
      " 14  group         12970 non-null  int64  \n",
      " 15  id            12970 non-null  int64  \n",
      " 16  deck          12671 non-null  object \n",
      " 17  cabin_no      12671 non-null  float64\n",
      " 18  side          12671 non-null  object \n",
      " 19  FName         12676 non-null  object \n",
      " 20  LName         12676 non-null  object \n",
      "dtypes: float64(8), int64(2), object(11)\n",
      "memory usage: 2.2+ MB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/pfv5w5hx4m904t97xs_9qv7m0000gn/T/ipykernel_84124/2749992746.py:39: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  all.Transported = all.Transported.replace({True: 1, False:0})\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering \n",
    "# split PassengerId column into its component parts (group, and id ) as separate features  \n",
    "all[['group', 'id']] = all['PassengerId'].str.split(pat='_', expand=True) \n",
    "\n",
    "# split Cabin column into its component parts (deck, cabin id, side ) as separate features \n",
    "all[['deck', 'cabin_no', 'side']] = all.Cabin.str.split('/', expand=True) \n",
    "\n",
    "# split Name column into its component parts (first and last name) as separate features\n",
    "all[['FName', 'LName']] = all.Name.str.split(\" \", expand=True) \n",
    "''' The intuition behind splitting name is that family name or first name may potentially \n",
    "have some influence on who gets transported into the anomaly '''\n",
    "\n",
    "# Treatment of High-cardinality columns : columns that have too many categories (eg. upwards of 25 categories) \n",
    "''' add value_counts column for high cardinality columns & then drop original col, and treat resulting values as numerical data \n",
    "alternatively, transform high_cardinality column data into numbers (ordinal encoding) and treat as numerical data '''\n",
    "\n",
    "# drop unique value columns  \n",
    "print(all.columns)\n",
    "\n",
    "# Subsetting columns for pre-processing with relevant encoders \n",
    "''' Since most machine learning models will require all data in numerical form, we will use relevant \n",
    "encoders to transform our data accordingly. Numerical columns will not undergo any encoding. \n",
    "Columns with ordinal values (ranks, value_counts, high-cardinality columns, etc) will be processed \n",
    "using Ordinal Encoder. Columns with categorical values (low-cardinality unique un-ordered values) \n",
    "to be OneHotEncoded, but we will first convert them into numerical codes (with Ordinal Encoder) so \n",
    "the whole dataset is already numerical for missing value imputation using an Imputation algorithms, \n",
    "eg. KNNImputer we have used here. '''\n",
    "\n",
    "numeric = ['Age', 'group', 'id', 'cabin_no', 'RoomService', 'FoodCourt', 'ShoppingMall','Spa','VRDeck',] \n",
    "ordinal = ['FName', 'LName'] \n",
    "categorical = ['HomePlanet', 'Destination', 'deck', 'side', 'CryoSleep', 'VIP', 'Transported'] \n",
    "\n",
    "# checking unique values in each categorical columns to address \n",
    "# any mistakes (such as due to spelling, uppercase-lowercase or similar errors,)\n",
    "uniq_cats = {col: sorted(all[col].dropna().unique().tolist() ) for col in categorical} \n",
    "# print(uniq_cats) \n",
    "\n",
    "# Converting target column booleans to corresponding Integer values \n",
    "all.Transported = all.Transported.replace({True: 1, False:0})\n",
    "\n",
    "# Viewing summary statistics for all columns to check for any un-natural (eg. negative values where there should be none, etc) values,\n",
    "print(all.describe(include='all').T)\n",
    "\n",
    "# converting into numeric dtypes where numbers are appearing as object datatype \n",
    "all[['group', 'id', 'cabin_no']] = all[['group', 'id', 'cabin_no']].apply(pd.to_numeric, axis=0)\n",
    "print(all.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cc55d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18\n",
      "Mean of target classes:  0.5036236051995858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Since this is a binary classification problem, calculating mean value of target column will suffice. \\nHere it is 0.503 indicating that the data very well balanced into positive and negative target classes. \\nIn case we had severely unbalanced data between target classes (say 0.75:0.25), we may have to address \\nthe imbalance, for example, by bootstrapping the minority class column to match the sample size of the \\nmajority class, or alternatively sampling from majority class column to match sample size of minority class'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping columns that have been split into their component values \n",
    "# setting original PassengerId column as row index \n",
    "all.set_index('PassengerId', inplace=True) \n",
    "\n",
    "# dropping Cabin & Name columns that were split previously \n",
    "all.drop(['Cabin', 'Name'], axis=1, inplace=True)\n",
    "\n",
    "# checking all columns in our dataset match with those covered under column groupings\n",
    "print(len(all.columns), len(numeric + ordinal + categorical) )\n",
    "\n",
    "# Transforming all NA value types (pandas, numpy NA types, etc) into np.nan type for uniformity \n",
    "all = all.fillna(np.nan) \n",
    "\n",
    "# Splitting our merged dataset into original train and test sets, \n",
    "# where original Test Set had missing ('NA') values in Transported column \n",
    "X_train = all[all.Transported.notna()].drop('Transported', axis=1)\n",
    "y_train = all[all.Transported.notna()].Transported.astype(int) \n",
    "X_test = all[all.Transported.isna()].drop('Transported', axis=1)\n",
    "\n",
    "# deleting the target column name from our categorical columns grouping list \n",
    "categorical.remove('Transported')\n",
    "\n",
    "# checking for data imbalance\n",
    "print('Mean of target classes: ', y_train.mean())\n",
    "\n",
    "''' Since this is a binary classification problem, calculating mean value of target column will suffice. \n",
    "Here it is 0.503 indicating that the data very well balanced into positive and negative target classes. \n",
    "In case we had severely unbalanced data between target classes (say 0.75:0.25), we may have to address \n",
    "the imbalance, for example, by bootstrapping the minority class column to match the sample size of the \n",
    "majority class, or alternatively sampling from majority class column to match sample size of minority class''' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d4d046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8693 entries, 0001_01 to 9280_02\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   HomePlanet    8492 non-null   float64\n",
      " 1   CryoSleep     8476 non-null   float64\n",
      " 2   Destination   8511 non-null   float64\n",
      " 3   Age           8514 non-null   float64\n",
      " 4   VIP           8490 non-null   float64\n",
      " 5   RoomService   8512 non-null   float64\n",
      " 6   FoodCourt     8510 non-null   float64\n",
      " 7   ShoppingMall  8485 non-null   float64\n",
      " 8   Spa           8510 non-null   float64\n",
      " 9   VRDeck        8505 non-null   float64\n",
      " 10  group         8693 non-null   int64  \n",
      " 11  id            8693 non-null   int64  \n",
      " 12  deck          8494 non-null   float64\n",
      " 13  cabin_no      8494 non-null   float64\n",
      " 14  side          8494 non-null   float64\n",
      " 15  FName         8493 non-null   float64\n",
      " 16  LName         8493 non-null   float64\n",
      "dtypes: float64(15), int64(2)\n",
      "memory usage: 1.4+ MB\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index: 8693 entries, 0001_01 to 9280_02\n",
      "Series name: Transported\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "8693 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 135.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4277 entries, 0013_01 to 9277_01\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   HomePlanet    4190 non-null   float64\n",
      " 1   CryoSleep     4184 non-null   float64\n",
      " 2   Destination   4185 non-null   float64\n",
      " 3   Age           4186 non-null   float64\n",
      " 4   VIP           4184 non-null   float64\n",
      " 5   RoomService   4195 non-null   float64\n",
      " 6   FoodCourt     4171 non-null   float64\n",
      " 7   ShoppingMall  4179 non-null   float64\n",
      " 8   Spa           4176 non-null   float64\n",
      " 9   VRDeck        4197 non-null   float64\n",
      " 10  group         4277 non-null   int64  \n",
      " 11  id            4277 non-null   int64  \n",
      " 12  deck          4177 non-null   float64\n",
      " 13  cabin_no      4177 non-null   float64\n",
      " 14  side          4177 non-null   float64\n",
      " 15  FName         3896 non-null   float64\n",
      " 16  LName         3759 non-null   float64\n",
      "dtypes: float64(15), int64(2)\n",
      "memory usage: 730.5+ KB\n",
      "None\n",
      "\n",
      "None\n",
      "\n",
      "None\n",
      "        HomePlanet    CryoSleep  Destination          Age          VIP  \\\n",
      "count  8492.000000  8476.000000  8511.000000  8514.000000  8490.000000   \n",
      "mean      0.665214     0.358306     1.483492    28.827930     0.023439   \n",
      "std       0.798155     0.479531     0.820237    14.489021     0.151303   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     1.000000    19.000000     0.000000   \n",
      "50%       0.000000     0.000000     2.000000    27.000000     0.000000   \n",
      "75%       1.000000     1.000000     2.000000    38.000000     0.000000   \n",
      "max       2.000000     1.000000     2.000000    79.000000     1.000000   \n",
      "\n",
      "        RoomService     FoodCourt  ShoppingMall           Spa        VRDeck  \\\n",
      "count   8512.000000   8510.000000   8485.000000   8510.000000   8505.000000   \n",
      "mean     224.687617    458.077203    173.729169    311.138778    304.854791   \n",
      "std      666.717663   1611.489240    604.696458   1136.705535   1145.717189   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%       47.000000     76.000000     27.000000     59.000000     46.000000   \n",
      "max    14327.000000  29813.000000  23492.000000  22408.000000  24133.000000   \n",
      "\n",
      "             group           id         deck     cabin_no         side  \\\n",
      "count  8693.000000  8693.000000  8494.000000  8494.000000  8494.000000   \n",
      "mean   4633.389624     1.517773     4.305392   600.367671     0.504827   \n",
      "std    2671.028856     1.054241     1.778233   511.867226     0.500006   \n",
      "min       1.000000     1.000000     0.000000     0.000000     0.000000   \n",
      "25%    2319.000000     1.000000     3.000000   167.250000     0.000000   \n",
      "50%    4630.000000     1.000000     5.000000   427.000000     1.000000   \n",
      "75%    6883.000000     2.000000     6.000000   999.000000     1.000000   \n",
      "max    9280.000000     8.000000     7.000000  1894.000000     1.000000   \n",
      "\n",
      "             FName        LName  \n",
      "count  8493.000000  8493.000000  \n",
      "mean   1344.921347  1110.891205  \n",
      "std     766.032078   641.481916  \n",
      "min       0.000000     0.000000  \n",
      "25%     710.000000   554.000000  \n",
      "50%    1346.000000  1110.000000  \n",
      "75%    1997.000000  1650.000000  \n",
      "max    2705.000000  2216.000000  \n",
      "\n",
      "count    8693.000000\n",
      "mean        0.503624\n",
      "std         0.500016\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         1.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: Transported, dtype: float64\n",
      "\n",
      "        HomePlanet    CryoSleep  Destination          Age          VIP  \\\n",
      "count  4190.000000  4184.000000  4185.000000  4186.000000  4184.000000   \n",
      "mean      0.680668     0.369025     1.505376    28.658146     0.017686   \n",
      "std       0.811815     0.482598     0.807489    14.179072     0.131825   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     1.000000    19.000000     0.000000   \n",
      "50%       0.000000     0.000000     2.000000    26.000000     0.000000   \n",
      "75%       1.000000     1.000000     2.000000    37.000000     0.000000   \n",
      "max       2.000000     1.000000     2.000000    79.000000     1.000000   \n",
      "\n",
      "        RoomService     FoodCourt  ShoppingMall           Spa        VRDeck  \\\n",
      "count   4195.000000   4171.000000   4179.000000   4176.000000   4197.000000   \n",
      "mean     219.266269    439.484296    177.295525    303.052443    310.710031   \n",
      "std      607.011289   1527.663045    560.821123   1117.186015   1246.994742   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%       53.000000     78.000000     33.000000     50.000000     36.000000   \n",
      "max    11567.000000  25273.000000   8292.000000  19844.000000  22272.000000   \n",
      "\n",
      "             group           id         deck     cabin_no         side  \\\n",
      "count  4277.000000  4277.000000  4177.000000  4177.000000  4177.000000   \n",
      "mean   4639.296469     1.498714     4.353603   610.178836     0.501077   \n",
      "std    2716.197368     1.018221     1.719892   514.968131     0.500059   \n",
      "min      13.000000     1.000000     0.000000     0.000000     0.000000   \n",
      "25%    2249.000000     1.000000     3.000000   174.000000     0.000000   \n",
      "50%    4639.000000     1.000000     5.000000   442.000000     1.000000   \n",
      "75%    7030.000000     2.000000     6.000000  1027.000000     1.000000   \n",
      "max    9277.000000     8.000000     7.000000  1890.000000     1.000000   \n",
      "\n",
      "             FName        LName  \n",
      "count  3896.000000  3759.000000  \n",
      "mean   1337.273614  1069.688215  \n",
      "std     758.085440   636.404377  \n",
      "min       0.000000     0.000000  \n",
      "25%     707.750000   509.000000  \n",
      "50%    1342.500000  1061.000000  \n",
      "75%    1979.250000  1601.000000  \n",
      "max    2705.000000  2216.000000  \n"
     ]
    }
   ],
   "source": [
    "# Using encoders on column groupings to convert data into numerical values where applicable \n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan) \n",
    "\n",
    "''' we will fit the encoders to training data and transform both training and test datasets using the \n",
    "same patterns learned from training data. This is to avoid leakage (of insights from test data (which \n",
    "is not available at the time of training in real world application) into training dataset) '''\n",
    "X_train[ordinal + categorical] = ordinal_encoder.fit_transform(X_train[ordinal + categorical]) \n",
    "X_test[ordinal + categorical] = ordinal_encoder.transform(X_test[ordinal + categorical])\n",
    "\n",
    "# check dtypes for each column and correct where necessary \n",
    "print(X_train.info(), y_train.info(), X_test.info(), sep = '\\n\\n')\n",
    "print(X_train.describe(), y_train.describe(), X_test.describe(), sep = '\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "205aeb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-Max spread of values in categorical columns: \n",
      " 0.0 7.0\n",
      "column-wise standard deviation in Training set after min-max scaling\n",
      "HomePlanet      0.798155\n",
      "CryoSleep       0.479531\n",
      "Destination     0.820237\n",
      "Age             1.283837\n",
      "VIP             0.151303\n",
      "RoomService     0.325750\n",
      "FoodCourt       0.378373\n",
      "ShoppingMall    0.180184\n",
      "Spa             0.355094\n",
      "VRDeck          0.332326\n",
      "group           2.015002\n",
      "id              1.054241\n",
      "deck            1.778233\n",
      "cabin_no        1.891801\n",
      "side            0.500006\n",
      "FName           1.982338\n",
      "LName           2.026342\n",
      "dtype: float64\n",
      "column-wise standard deviation in Test set after min-max scaling\n",
      "HomePlanet      0.811815\n",
      "CryoSleep       0.482598\n",
      "Destination     0.807489\n",
      "Age             1.256373\n",
      "VIP             0.131825\n",
      "RoomService     0.296578\n",
      "FoodCourt       0.358691\n",
      "ShoppingMall    0.167110\n",
      "Spa             0.348996\n",
      "VRDeck          0.361702\n",
      "group           2.049077\n",
      "id              1.018221\n",
      "deck            1.719892\n",
      "cabin_no        1.903261\n",
      "side            0.500059\n",
      "FName           1.961774\n",
      "LName           2.010303\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# calculate min & max values for all categorical features combined \n",
    "min_cat = X_train[categorical].min().min()\n",
    "max_cat = X_train[categorical].max().max()\n",
    "print('Min-Max spread of values in categorical columns: \\n', min_cat, max_cat) \n",
    "\n",
    "# Scaling using MinMaxScaler \n",
    "mmScaler = MinMaxScaler(feature_range=(min_cat, max_cat)) \n",
    "X_train[numeric + ordinal] = mmScaler.fit_transform(X_train[numeric + ordinal]) \n",
    "X_test[numeric + ordinal] = mmScaler.transform(X_test[numeric + ordinal]) \n",
    "\n",
    "# checking column-wise standard deviation for scaled data \n",
    "print('column-wise standard deviation in Training set after min-max scaling')\n",
    "print(X_train.std(axis=0).T)\n",
    "print('column-wise standard deviation in Test set after min-max scaling')\n",
    "print(X_test.std(axis=0).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ec666fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/se411/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/envs/se411/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/envs/se411/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/envs/se411/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/envs/se411/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/anaconda3/envs/se411/lib/python3.13/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet      0\n",
      "CryoSleep       0\n",
      "Destination     0\n",
      "Age             0\n",
      "VIP             0\n",
      "RoomService     0\n",
      "FoodCourt       0\n",
      "ShoppingMall    0\n",
      "Spa             0\n",
      "VRDeck          0\n",
      "group           0\n",
      "id              0\n",
      "deck            0\n",
      "cabin_no        0\n",
      "side            0\n",
      "FName           0\n",
      "LName           0\n",
      "dtype: int64\n",
      "HomePlanet      0\n",
      "CryoSleep       0\n",
      "Destination     0\n",
      "Age             0\n",
      "VIP             0\n",
      "RoomService     0\n",
      "FoodCourt       0\n",
      "ShoppingMall    0\n",
      "Spa             0\n",
      "VRDeck          0\n",
      "group           0\n",
      "id              0\n",
      "deck            0\n",
      "cabin_no        0\n",
      "side            0\n",
      "FName           0\n",
      "LName           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Using KNN Imputer to impute missing values \n",
    "\n",
    "# ensure all NA values are represented uniformluy as np.nan \n",
    "X_train = X_train.fillna(np.nan)\n",
    "X_test = X_test.fillna(np.nan) \n",
    "\n",
    "# Instantiate KNNImputer using default 5 neighbors \n",
    "imputer = KNNImputer(n_neighbors=5) \n",
    "\n",
    "'''KNN Imputer will return numpy arrays. In order to retain our dataframe with column names \n",
    "(to use for further preprocessig), we will assign the numpy output to our pandas dataframes \n",
    "using .loc[:] accessor for all data. '''\n",
    "\n",
    "X_train.loc[:] = imputer.fit_transform(X_train) \n",
    "X_test.loc[:] = imputer.transform(X_test) \n",
    "\n",
    "# Checking if any missing values still remain \n",
    "print(X_train.isna().sum().T) \n",
    "print(X_test.isna().sum().T) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "219e304c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f570f_row0_col0, #T_f570f_row0_col1 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f570f_row1_col0 {\n",
       "  background-color: #6ba5cd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f570f_row1_col1 {\n",
       "  background-color: #67a4cc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f570f_row2_col0, #T_f570f_row11_col1 {\n",
       "  background-color: #83afd3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f570f_row2_col1 {\n",
       "  background-color: #2a88bc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f570f_row3_col0 {\n",
       "  background-color: #8eb3d5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row3_col1 {\n",
       "  background-color: #6fa7ce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f570f_row4_col0, #T_f570f_row14_col1 {\n",
       "  background-color: #d2d2e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row4_col1 {\n",
       "  background-color: #e0deed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row5_col0 {\n",
       "  background-color: #d2d3e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row5_col1 {\n",
       "  background-color: #d3d4e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row6_col0 {\n",
       "  background-color: #d7d6e9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row6_col1 {\n",
       "  background-color: #ebe6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row7_col0, #T_f570f_row15_col1 {\n",
       "  background-color: #d9d8ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row7_col1, #T_f570f_row8_col0, #T_f570f_row8_col1 {\n",
       "  background-color: #e8e4f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row9_col0 {\n",
       "  background-color: #ece7f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row9_col1 {\n",
       "  background-color: #faf2f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row10_col0, #T_f570f_row11_col0 {\n",
       "  background-color: #f2ecf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row10_col1 {\n",
       "  background-color: #f1ebf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row12_col0 {\n",
       "  background-color: #f5eff6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row12_col1, #T_f570f_row15_col0, #T_f570f_row16_col0 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row13_col0 {\n",
       "  background-color: #fbf3f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row13_col1 {\n",
       "  background-color: #dbdaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row14_col0 {\n",
       "  background-color: #fdf5fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f570f_row16_col1 {\n",
       "  background-color: #b0c2de;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f570f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f570f_level0_col0\" class=\"col_heading level0 col0\" >correlation</th>\n",
       "      <th id=\"T_f570f_level0_col1\" class=\"col_heading level0 col1\" >mutual_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row0\" class=\"row_heading level0 row0\" >CryoSleep</th>\n",
       "      <td id=\"T_f570f_row0_col0\" class=\"data row0 col0\" >0.464822</td>\n",
       "      <td id=\"T_f570f_row0_col1\" class=\"data row0 col1\" >0.122334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row1\" class=\"row_heading level0 row1\" >RoomService</th>\n",
       "      <td id=\"T_f570f_row1_col0\" class=\"data row1 col0\" >0.243517</td>\n",
       "      <td id=\"T_f570f_row1_col1\" class=\"data row1 col1\" >0.064168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row2\" class=\"row_heading level0 row2\" >Spa</th>\n",
       "      <td id=\"T_f570f_row2_col0\" class=\"data row2 col0\" >0.218882</td>\n",
       "      <td id=\"T_f570f_row2_col1\" class=\"data row2 col1\" >0.080261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row3\" class=\"row_heading level0 row3\" >VRDeck</th>\n",
       "      <td id=\"T_f570f_row3_col0\" class=\"data row3 col0\" >0.206177</td>\n",
       "      <td id=\"T_f570f_row3_col1\" class=\"data row3 col1\" >0.062403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row4\" class=\"row_heading level0 row4\" >HomePlanet</th>\n",
       "      <td id=\"T_f570f_row4_col0\" class=\"data row4 col0\" >0.119572</td>\n",
       "      <td id=\"T_f570f_row4_col1\" class=\"data row4 col1\" >0.021771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row5\" class=\"row_heading level0 row5\" >deck</th>\n",
       "      <td id=\"T_f570f_row5_col0\" class=\"data row5 col0\" >0.117175</td>\n",
       "      <td id=\"T_f570f_row5_col1\" class=\"data row5 col1\" >0.028820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row6\" class=\"row_heading level0 row6\" >Destination</th>\n",
       "      <td id=\"T_f570f_row6_col0\" class=\"data row6 col0\" >0.109219</td>\n",
       "      <td id=\"T_f570f_row6_col1\" class=\"data row6 col1\" >0.016185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row7\" class=\"row_heading level0 row7\" >side</th>\n",
       "      <td id=\"T_f570f_row7_col0\" class=\"data row7 col0\" >0.103062</td>\n",
       "      <td id=\"T_f570f_row7_col1\" class=\"data row7 col1\" >0.017440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row8\" class=\"row_heading level0 row8\" >Age</th>\n",
       "      <td id=\"T_f570f_row8_col0\" class=\"data row8 col0\" >0.072878</td>\n",
       "      <td id=\"T_f570f_row8_col1\" class=\"data row8 col1\" >0.017640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row9\" class=\"row_heading level0 row9\" >id</th>\n",
       "      <td id=\"T_f570f_row9_col0\" class=\"data row9 col0\" >0.066390</td>\n",
       "      <td id=\"T_f570f_row9_col1\" class=\"data row9 col1\" >0.004860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row10\" class=\"row_heading level0 row10\" >cabin_no</th>\n",
       "      <td id=\"T_f570f_row10_col0\" class=\"data row10 col0\" >0.046197</td>\n",
       "      <td id=\"T_f570f_row10_col1\" class=\"data row10 col1\" >0.011762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row11\" class=\"row_heading level0 row11\" >FoodCourt</th>\n",
       "      <td id=\"T_f570f_row11_col0\" class=\"data row11 col0\" >0.046167</td>\n",
       "      <td id=\"T_f570f_row11_col1\" class=\"data row11 col1\" >0.056758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row12\" class=\"row_heading level0 row12\" >VIP</th>\n",
       "      <td id=\"T_f570f_row12_col0\" class=\"data row12 col0\" >0.036606</td>\n",
       "      <td id=\"T_f570f_row12_col1\" class=\"data row12 col1\" >0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row13\" class=\"row_heading level0 row13\" >group</th>\n",
       "      <td id=\"T_f570f_row13_col0\" class=\"data row13 col0\" >0.021491</td>\n",
       "      <td id=\"T_f570f_row13_col1\" class=\"data row13 col1\" >0.024614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row14\" class=\"row_heading level0 row14\" >LName</th>\n",
       "      <td id=\"T_f570f_row14_col0\" class=\"data row14 col0\" >0.015498</td>\n",
       "      <td id=\"T_f570f_row14_col1\" class=\"data row14 col1\" >0.030119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row15\" class=\"row_heading level0 row15\" >FName</th>\n",
       "      <td id=\"T_f570f_row15_col0\" class=\"data row15 col0\" >0.009261</td>\n",
       "      <td id=\"T_f570f_row15_col1\" class=\"data row15 col1\" >0.025595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f570f_level0_row16\" class=\"row_heading level0 row16\" >ShoppingMall</th>\n",
       "      <td id=\"T_f570f_row16_col0\" class=\"data row16 col0\" >0.007738</td>\n",
       "      <td id=\"T_f570f_row16_col1\" class=\"data row16 col1\" >0.042414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17fdf81a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics after missing value imputation: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8693 entries, 0001_01 to 9280_02\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   HomePlanet    8693 non-null   float64\n",
      " 1   CryoSleep     8693 non-null   float64\n",
      " 2   Destination   8693 non-null   float64\n",
      " 3   Age           8693 non-null   float64\n",
      " 4   VIP           8693 non-null   float64\n",
      " 5   RoomService   8693 non-null   float64\n",
      " 6   FoodCourt     8693 non-null   float64\n",
      " 7   ShoppingMall  8693 non-null   float64\n",
      " 8   Spa           8693 non-null   float64\n",
      " 9   VRDeck        8693 non-null   float64\n",
      " 10  group         8693 non-null   float64\n",
      " 11  id            8693 non-null   float64\n",
      " 12  deck          8693 non-null   float64\n",
      " 13  cabin_no      8693 non-null   float64\n",
      " 14  side          8693 non-null   float64\n",
      " 15  FName         8693 non-null   float64\n",
      " 16  LName         8693 non-null   float64\n",
      "dtypes: float64(17)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "               count      mean       std  min       25%       50%       75%  \\\n",
      "HomePlanet    8693.0  0.663407  0.793190  0.0  0.000000  0.000000  1.000000   \n",
      "CryoSleep     8693.0  0.359117  0.475694  0.0  0.000000  0.000000  1.000000   \n",
      "Destination   8693.0  1.484988  0.813339  0.0  1.000000  2.000000  2.000000   \n",
      "Age           8693.0  2.554257  1.274142  0.0  1.683544  2.392405  3.367089   \n",
      "VIP           8693.0  0.023214  0.149795  0.0  0.000000  0.000000  0.000000   \n",
      "RoomService   8693.0  0.109874  0.323254  0.0  0.000000  0.000000  0.028338   \n",
      "FoodCourt     8693.0  0.107324  0.375431  0.0  0.000000  0.000000  0.020662   \n",
      "ShoppingMall  8693.0  0.051620  0.178397  0.0  0.000000  0.000000  0.009535   \n",
      "Spa           8693.0  0.097355  0.352030  0.0  0.000000  0.000000  0.022804   \n",
      "VRDeck        8693.0  0.088063  0.329733  0.0  0.000000  0.000000  0.015373   \n",
      "group         8693.0  3.494636  2.015002  0.0  1.748680  3.492079  5.191723   \n",
      "id            8693.0  0.517773  1.054241  0.0  0.000000  0.000000  1.000000   \n",
      "deck          8693.0  4.306476  1.770726  0.0  3.000000  5.000000  6.000000   \n",
      "cabin_no      8693.0  2.213791  1.883950  0.0  0.620908  1.581837  3.673706   \n",
      "side          8693.0  0.505326  0.495359  0.0  0.000000  0.600000  1.000000   \n",
      "FName         8693.0  3.482787  1.964260  0.0  1.863216  3.490943  5.123845   \n",
      "LName         8693.0  3.507923  2.007687  0.0  1.787906  3.506318  5.180505   \n",
      "\n",
      "              max  \n",
      "HomePlanet    2.0  \n",
      "CryoSleep     1.0  \n",
      "Destination   2.0  \n",
      "Age           7.0  \n",
      "VIP           1.0  \n",
      "RoomService   7.0  \n",
      "FoodCourt     7.0  \n",
      "ShoppingMall  7.0  \n",
      "Spa           7.0  \n",
      "VRDeck        7.0  \n",
      "group         7.0  \n",
      "id            7.0  \n",
      "deck          7.0  \n",
      "cabin_no      7.0  \n",
      "side          1.0  \n",
      "FName         7.0  \n",
      "LName         7.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4277 entries, 0013_01 to 9277_01\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   HomePlanet    4277 non-null   float64\n",
      " 1   CryoSleep     4277 non-null   float64\n",
      " 2   Destination   4277 non-null   float64\n",
      " 3   Age           4277 non-null   float64\n",
      " 4   VIP           4277 non-null   float64\n",
      " 5   RoomService   4277 non-null   float64\n",
      " 6   FoodCourt     4277 non-null   float64\n",
      " 7   ShoppingMall  4277 non-null   float64\n",
      " 8   Spa           4277 non-null   float64\n",
      " 9   VRDeck        4277 non-null   float64\n",
      " 10  group         4277 non-null   float64\n",
      " 11  id            4277 non-null   float64\n",
      " 12  deck          4277 non-null   float64\n",
      " 13  cabin_no      4277 non-null   float64\n",
      " 14  side          4277 non-null   float64\n",
      " 15  FName         4277 non-null   float64\n",
      " 16  LName         4277 non-null   float64\n",
      "dtypes: float64(17)\n",
      "memory usage: 730.5+ KB\n",
      "None\n",
      "               count      mean       std       min       25%       50%  \\\n",
      "HomePlanet    4277.0  0.679448  0.806186  0.000000  0.000000  0.000000   \n",
      "CryoSleep     4277.0  0.369698  0.479142  0.000000  0.000000  0.000000   \n",
      "Destination   4277.0  1.506710  0.801334  0.000000  1.000000  2.000000   \n",
      "Age           4277.0  2.541217  1.246635  0.000000  1.772152  2.303797   \n",
      "VIP           4277.0  0.017816  0.130805  0.000000  0.000000  0.000000   \n",
      "RoomService   4277.0  0.106932  0.294393  0.000000  0.000000  0.000000   \n",
      "FoodCourt     4277.0  0.102653  0.355811  0.000000  0.000000  0.000000   \n",
      "ShoppingMall  4277.0  0.053220  0.166964  0.000000  0.000000  0.000000   \n",
      "Spa           4277.0  0.094317  0.345609  0.000000  0.000000  0.000000   \n",
      "VRDeck        4277.0  0.089385  0.358569  0.000000  0.000000  0.000000   \n",
      "group         4277.0  3.499092  2.049077  0.009053  1.695872  3.498868   \n",
      "id            4277.0  0.498714  1.018221  0.000000  0.000000  0.000000   \n",
      "deck          4277.0  4.360393  1.710030  0.000000  3.000000  5.000000   \n",
      "cabin_no      4277.0  2.266319  1.898600  0.000000  0.654171  1.655755   \n",
      "side          4277.0  0.500351  0.494982  0.000000  0.000000  0.600000   \n",
      "FName         4277.0  3.467896  1.891856  0.000000  1.922736  3.488355   \n",
      "LName         4277.0  3.399559  1.910540  0.000000  1.825812  3.411552   \n",
      "\n",
      "                   75%       max  \n",
      "HomePlanet    1.000000  2.000000  \n",
      "CryoSleep     1.000000  1.000000  \n",
      "Destination   2.000000  2.000000  \n",
      "Age           3.278481  7.000000  \n",
      "VIP           0.000000  1.000000  \n",
      "RoomService   0.029804  5.651497  \n",
      "FoodCourt     0.021132  5.934022  \n",
      "ShoppingMall  0.011919  2.470799  \n",
      "Spa           0.019368  6.199036  \n",
      "VRDeck        0.011892  6.460200  \n",
      "group         5.302619  6.997737  \n",
      "id            1.000000  7.000000  \n",
      "deck          6.000000  7.000000  \n",
      "cabin_no      3.803062  6.985216  \n",
      "side          1.000000  1.000000  \n",
      "FName         4.971165  7.000000  \n",
      "LName         4.880415  7.000000  \n"
     ]
    }
   ],
   "source": [
    "# Calculating correlation (linear) and mutual-info (non-linear) of dataset columns / features with target column \n",
    "correlation = pd.concat([X_train, y_train], axis=1).corr().Transported.abs().values[:-1]\n",
    "mutual_info = mutual_info_regression(X_train, y_train, random_state=SEED) \n",
    "associations = {'correlation': correlation, 'mutual_info': mutual_info} \n",
    "associations = pd.DataFrame(associations, index=X_train.columns).sort_values(by='correlation', ascending=False)\n",
    "display(associations.style.background_gradient() )\n",
    "\n",
    "# Checking summary statistics after missing value imputation \n",
    "print('Summary statistics after missing value imputation: ') \n",
    "print(X_train.info(), X_train.describe().T, sep='\\n') \n",
    "print(X_test.info(), X_test.describe().T, sep='\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c4e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OHE\n",
      "(8693, 17)\n",
      "(4277, 17)\n",
      "After OHE\n",
      "(8693, 69)\n",
      "(4277, 69)\n",
      "[6954, 1739, 6954, 1739, 6954, 1739]\n",
      "SEED:  50309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/se411/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [0, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Transforming Categorical features using OneHotEncoder \n",
    "print('Before OHE', X_train.shape, X_test.shape, sep='\\n')\n",
    "onehot = OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False) \n",
    "onehot = make_column_transformer((onehot, categorical), remainder='passthrough')\n",
    "X_train = onehot.fit_transform(X_train)\n",
    "X_test = onehot.transform(X_test) \n",
    "print('After OHE', X_train.shape, X_test.shape, sep='\\n')\n",
    "\n",
    "\n",
    "# scaler = StandardScaler(with_mean=True)\n",
    "scaler = RobustScaler(with_centering=True)\n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "# Retaining full training set for training model to be used for submission  \n",
    "X_train_full, y_train_full = X_train.copy(), y_train.copy()\n",
    "\n",
    "# Creating training and validation split (including corresponding indices from the base set) to evaluate model performances \n",
    "X_train, X_val, y_train, y_val, tts_tr, tts_val = train_test_split(X_train_full, y_train_full, np.arange(X_train_full.shape[0]), \n",
    "                                                                   test_size=0.20, stratify=y_train_full, random_state=SEED) \n",
    "print([i.shape[0] for i in [X_train, X_val, y_train, y_val, tts_tr, tts_val] ]) \n",
    "print('SEED: ', SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e061300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_dict = dict() # to save separate predictions basis shuffled splits of training data \n",
    "n_splits = 5 # no of shuffled splits of data we will try "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d998a4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/pfv5w5hx4m904t97xs_9qv7m0000gn/T/ipykernel_84124/3152141321.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  model = model.fit(X_train_full[tr_ids], y_train_full[tr_ids] )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak oob cum. improv:  0.9832589663906399 0.9832589663906399\n",
      "Before n_est tuning: 0: 0.9737011769586532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/pfv5w5hx4m904t97xs_9qv7m0000gn/T/ipykernel_84124/3152141321.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  model = model.fit(X_train_full[tr_ids], y_train_full[tr_ids])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak oob cum. improv:  0.9434832178930596 0.9434832178930596\n",
      "After n_est tuning: 0: 0.9235796954983999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/pfv5w5hx4m904t97xs_9qv7m0000gn/T/ipykernel_84124/3152141321.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  model = model.fit(X_train_full[tr_ids], y_train_full[tr_ids] )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak oob cum. improv:  0.9686328938265619 0.9686328938265619\n",
      "Before n_est tuning: 1: 0.9625641075759549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/pfv5w5hx4m904t97xs_9qv7m0000gn/T/ipykernel_84124/3152141321.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  model = model.fit(X_train_full[tr_ids], y_train_full[tr_ids])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak oob cum. improv:  0.9390674934881882 0.9390674934881882\n",
      "After n_est tuning: 1: 0.9133271188277623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/pfv5w5hx4m904t97xs_9qv7m0000gn/T/ipykernel_84124/3152141321.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  model = model.fit(X_train_full[tr_ids], y_train_full[tr_ids] )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak oob cum. improv:  0.9584120771772768 0.9584120771772768\n",
      "Before n_est tuning: 2: 0.9354749732552889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/pfv5w5hx4m904t97xs_9qv7m0000gn/T/ipykernel_84124/3152141321.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  model = model.fit(X_train_full[tr_ids], y_train_full[tr_ids])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak oob cum. improv:  0.9196724117423961 0.9196724117423961\n",
      "After n_est tuning: 2: 0.8993104603373239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/pfv5w5hx4m904t97xs_9qv7m0000gn/T/ipykernel_84124/3152141321.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  model = model.fit(X_train_full[tr_ids], y_train_full[tr_ids] )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak oob cum. improv:  0.8920875762731622 0.8920875762731622\n",
      "Before n_est tuning: 3: 0.8822716489238389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/pfv5w5hx4m904t97xs_9qv7m0000gn/T/ipykernel_84124/3152141321.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  model = model.fit(X_train_full[tr_ids], y_train_full[tr_ids])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak oob cum. improv:  0.8509548324066896 0.8509548324066896\n",
      "After n_est tuning: 3: 0.8414089459574485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/pfv5w5hx4m904t97xs_9qv7m0000gn/T/ipykernel_84124/3152141321.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  model = model.fit(X_train_full[tr_ids], y_train_full[tr_ids] )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak oob cum. improv:  0.9182285439050208 0.9182285439050208\n",
      "Before n_est tuning: 4: 0.8925148352351902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/pfv5w5hx4m904t97xs_9qv7m0000gn/T/ipykernel_84124/3152141321.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  model = model.fit(X_train_full[tr_ids], y_train_full[tr_ids])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak oob cum. improv:  0.8571759911467728 0.8571759911467728\n",
      "After n_est tuning: 4: 0.852780471214627\n",
      "             gbc_0        gbc_1        gbc_2        gbc_3        gbc_4  \\\n",
      "count  4277.000000  4277.000000  4277.000000  4277.000000  4277.000000   \n",
      "mean      0.504877     0.501223     0.504382     0.504965     0.502580   \n",
      "std       0.355613     0.355872     0.352190     0.341037     0.345424   \n",
      "min       0.001557     0.001232     0.004371     0.004417     0.001755   \n",
      "25%       0.127034     0.126333     0.131439     0.145072     0.135698   \n",
      "50%       0.510803     0.510591     0.519956     0.517604     0.515690   \n",
      "75%       0.883004     0.883550     0.875220     0.854289     0.857246   \n",
      "max       0.995431     0.995659     0.994472     0.990830     0.994375   \n",
      "\n",
      "            gb_avg  \n",
      "count  4277.000000  \n",
      "mean      0.503606  \n",
      "std       0.347406  \n",
      "min       0.003065  \n",
      "25%       0.135924  \n",
      "50%       0.518557  \n",
      "75%       0.864757  \n",
      "max       0.993035  \n",
      "[1. 0. 1. 1. 1.]\n",
      "0.5155482815057283\n",
      "SEED: 50309\n",
      "gbc_0     323\n",
      "gbc_1     309\n",
      "gbc_2     323\n",
      "gbc_3     344\n",
      "gbc_4     366\n",
      "gb_avg    351\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Tuned GradientBoostingClassifier with early stopping basis validation set \n",
    "'''Minimizing over-fitting, improving model generalization while using maximum possible training data for fitting our model ''' \n",
    "sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=2, random_state=SEED, ) \n",
    "\n",
    "for i, (tr_ids, ts_ids) in enumerate(sss.split(X_train_full, y_train_full)): \n",
    "    # training on shuffled dataset with 0.2 validation_fraction \n",
    "    model = GradientBoostingClassifier(max_depth=7, max_features='sqrt', n_estimators=600, n_iter_no_change=50, tol=0, subsample=0.75, learning_rate=0.05, validation_fraction=0.2, verbose=0, random_state=SEED+i )\n",
    "    model = model.fit(X_train_full[tr_ids], y_train_full[tr_ids] ) \n",
    "    # Checking OOB scores \n",
    "    raw_ests = model.n_estimators_ \n",
    "    opt_ests = np.argmax(np.cumsum(model.oob_improvement_)) + 1 \n",
    "    estop_ests = raw_ests - model.n_iter_no_change \n",
    "#     print(opt_ests, raw_ests, sep=' / ' )\n",
    "    print('Peak oob cum. improv: ', np.max(np.cumsum(model.oob_improvement_)), np.cumsum(model.oob_improvement_)[opt_ests-1] )\n",
    "    print('Before n_est tuning', i, np.sum(model.oob_improvement_), sep=': ')\n",
    "#     print(i, 'log_loss', log_loss(y_train_full[ts_ids], model.predict_proba(X_train_full[ts_ids])[:,1])) \n",
    "#     print(i, 'accuracy', model.score(X_train_full[ts_ids], y_train_full[ts_ids]), '\\n') \n",
    "    \n",
    "    ''' To refit the model using n_estimators corresponding to peak cum. improvement, use n_estimators=opt_ests '''\n",
    "    \n",
    "    # Refit the model using n_estimators = raw_ests - early stopping \n",
    "    model = GradientBoostingClassifier(max_depth=7, max_features='sqrt', n_estimators=estop_ests, n_iter_no_change=50, tol=0, subsample=0.75, learning_rate=0.05, validation_fraction=0.2, verbose=0, random_state=SEED+i) \n",
    "    model = model.fit(X_train_full[tr_ids], y_train_full[tr_ids]) \n",
    "    # Checking OOB scores \n",
    "    opt_ests = np.argmax(np.cumsum(model.oob_improvement_)) + 1 \n",
    "#     print(opt_ests, model.n_estimators_, sep=' / ' )\n",
    "    print('Peak oob cum. improv: ', np.max(np.cumsum(model.oob_improvement_)), np.cumsum(model.oob_improvement_)[opt_ests-1] )\n",
    "    print('After n_est tuning', i, np.sum(model.oob_improvement_), sep=': ')\n",
    "#     print(i, 'log_loss', log_loss(y_train_full[ts_ids], model.predict_proba(X_train_full[ts_ids])[:,1])) \n",
    "#     print(i, 'accuracy', model.score(X_train_full[ts_ids], y_train_full[ts_ids]), '\\n') \n",
    "\n",
    "    # predict on test set using model trained on StratifiedShuffleSplit of training data with 0.2 validation_fraction \n",
    "    pred_dict['gbc_'+str(i)] = model.predict_proba(X_test)[:, 1] \n",
    "    \n",
    "predict_frame = pd.DataFrame(pred_dict)\n",
    "predict_frame['gb_avg'] = predict_frame.iloc[:,-n_splits:].mean(axis=1) # soft voting gives better results than hard voting \n",
    "# predict_frame['gb_avg'] = predict_frame.median(axis=1) # hard voting  \n",
    "print(predict_frame.describe()) \n",
    "\n",
    "y_test_pred = np.round(predict_frame['gb_avg'].values)  \n",
    "# y_test_pred = np.round(predict_frame[2].values)  \n",
    "print(y_test_pred[:5]) \n",
    "print(np.mean(y_test_pred)) \n",
    "\n",
    "submission = pd.DataFrame(dict(PassengerId = test.PassengerId, Transported = y_test_pred)) \n",
    "submission.Transported = submission.Transported.astype('bool')\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head() \n",
    "\n",
    "print('SEED:', SEED) # to see THE random seed used in this run \n",
    "print ( ((predict_frame > 0.45) & (predict_frame < 0.55)).sum() )\n",
    "# print(model.__dict__) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a477b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.514145429039046\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01         True\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01         True\n",
       "4     0023_01         True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Use this code block to generate a quick submission using any specified model \n",
    "set_random_seed = SEED \n",
    "y_test_pred = GradientBoostingClassifier(learning_rate=0.05, max_depth=7, max_features='log2', n_estimators=154, \n",
    "                                    subsample=0.55).fit(X_train_full, y_train_full).predict(X_test) # 0.80406 V15 \n",
    "print(np.mean(y_test_pred)) \n",
    "submission = pd.DataFrame(dict(PassengerId = test.PassengerId, Transported = y_test_pred)) \n",
    "submission.Transported = submission.Transported.astype('bool')\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se411",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
